{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make LSTMs Great Again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition on Twitter Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corpus contains tweets and named entity tags. A line in corpus is a token with a tag separated by a space.\n",
    "\n",
    "Different tweets are separated by a new line.\n",
    "\n",
    "Replace usernames that starts with @ with USR and url that starts with 'http:// || https://' with URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_path):\n",
    "    tokens = [] # List of list of words in a tweet, for all tweets\n",
    "    tags = [] # List of list of tags in a tweet, for all tags corresponding to the tweet\n",
    "    \n",
    "    tweet_tokens = []\n",
    "    tweet_tags = []\n",
    "    for line in open(file_path, encoding='utf-8'):  \n",
    "        line = line.strip() # remove leading and trailing space\n",
    "        if not line:\n",
    "            if tweet_tokens:\n",
    "                tokens.append(tweet_tokens)\n",
    "                tags.append(tweet_tags)\n",
    "            tweet_tokens = []\n",
    "            tweet_tags = []\n",
    "        else:\n",
    "            token, tag = line.split()\n",
    "            if token.startswith(\"@\"):\n",
    "                token=\"<USR>\" # Replace username with <USR>\n",
    "            elif token.startswith(\"http://\") or token.startswith(\"https://\"):\n",
    "                token=\"<URL>\" # Replace links with <URL>\n",
    "            tweet_tokens.append(token)\n",
    "            tweet_tags.append(tag)\n",
    "            \n",
    "    return tokens, tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Train, Validation and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokens, train_tags = read_data('Data/train.txt')\n",
    "validation_tokens, validation_tags = read_data('Data/validation.txt')\n",
    "test_tokens, test_tags = read_data('Data/test.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT <USR> : Online ticket sales for Ghostland Observatory extended until 6 PM EST due to high demand . Get them before they sell out ... "
     ]
    }
   ],
   "source": [
    "for word in train_tokens[0]: print(word, end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O O O O O O O B-musicartist I-musicartist O O O O O O O O O O O O O O O O O "
     ]
    }
   ],
   "source": [
    "for tag in train_tags[0]: print(tag, end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each element loaded to train tokens is a tweet, which in turn is a list of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 5795 tweets\n"
     ]
    }
   ],
   "source": [
    "print(\"We have\", len(train_tokens), \"tweets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for missing tags/tweet in the test, train and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data all set\n"
     ]
    }
   ],
   "source": [
    "if len(train_tokens) != len(train_tags): print(\"train mismatch\")\n",
    "elif len(validation_tokens) != len(validation_tags): print(\"validation mismatch\")\n",
    "elif len(test_tokens) != len(test_tags): print(\"test mismatch\")\n",
    "else: \n",
    "    all_right = 1\n",
    "    print(\"Data all set\")\n",
    "assert all_right == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need 2 mappings for training the NN\n",
    "\n",
    "1. token --> tokenID\n",
    "2. tag --> tagID\n",
    "\n",
    "tokenID addresses the row in the embedding matrix\n",
    "\n",
    "tagID is the ID of the tag - to getDummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def build_dict(tokens_or_tags, special_tokens):\n",
    "#     tokens_or_tags is list of list of tokens/tags\n",
    "#     special_tokens are some special tokens\n",
    "    # Create a dict with default value 0\n",
    "    tok2idx = defaultdict(lambda: 0)\n",
    "    idx2tok = []\n",
    "    k = 0\n",
    "    \n",
    "    for line in special_tokens:\n",
    "        tok2idx[line] = k\n",
    "        k += 1\n",
    "        idx2tok.append(line)\n",
    "        \n",
    "    for tokens in tokens_or_tags:\n",
    "        for token in tokens:\n",
    "            if token not in tok2idx:\n",
    "                tok2idx[token] = k\n",
    "                k += 1\n",
    "                idx2tok.append(token)\n",
    "    return tok2idx, idx2tok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Special Tokens:\n",
    "\n",
    "UNK : Unknown tokens - the ones found outside of the vocabulary\n",
    "\n",
    "PAD : Padding the sentence to the same length to create batches of sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_tokens = ['<UNK>', '<PAD>']\n",
    "special_tags = ['O']\n",
    "\n",
    "# Create the Dictionaries\n",
    "token2idx, idx2token = build_dict(train_tokens + validation_tokens, special_tokens) # for tokens\n",
    "tag2idx, idx2tag = build_dict(train_tags, special_tags) # for tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.build_dict.<locals>.<lambda>()>,\n",
       "            {'O': 0,\n",
       "             'B-musicartist': 1,\n",
       "             'I-musicartist': 2,\n",
       "             'B-product': 3,\n",
       "             'I-product': 4,\n",
       "             'B-company': 5,\n",
       "             'B-person': 6,\n",
       "             'B-other': 7,\n",
       "             'I-other': 8,\n",
       "             'B-facility': 9,\n",
       "             'I-facility': 10,\n",
       "             'B-sportsteam': 11,\n",
       "             'B-geo-loc': 12,\n",
       "             'I-geo-loc': 13,\n",
       "             'I-company': 14,\n",
       "             'I-person': 15,\n",
       "             'B-movie': 16,\n",
       "             'I-movie': 17,\n",
       "             'B-tvshow': 18,\n",
       "             'I-tvshow': 19,\n",
       "             'I-sportsteam': 20})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag2idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 19 named entity tag along with a non_named_entity tag denoted by O"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to create the mapping between tokens and IDs for a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words2idxs(tokens_list):\n",
    "    return [token2idx[word] for word in tokens_list]\n",
    "\n",
    "def tags2idxs(tags_list):\n",
    "    return [tag2idx[tag] for tag in tags_list]\n",
    "\n",
    "def idxs2words(idxs):\n",
    "    return [idx2token[idx] for idx in idxs]\n",
    "\n",
    "def idxs2tags(idxs):\n",
    "    return [idx2tag[idx] for idx in idxs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batches_generator(batch_size, tokens, tags,\n",
    "                      shuffle=True, allow_smaller_last_batch=True):\n",
    "    \"\"\"Generates padded batches of tokens and tags.\"\"\"\n",
    "    \n",
    "    n_samples = len(tokens)\n",
    "    if shuffle:\n",
    "        order = np.random.permutation(n_samples)\n",
    "    else:\n",
    "        order = np.arange(n_samples)\n",
    "\n",
    "    n_batches = n_samples // batch_size\n",
    "    if allow_smaller_last_batch and n_samples % batch_size:\n",
    "        n_batches += 1\n",
    "\n",
    "    for k in range(n_batches):\n",
    "        batch_start = k * batch_size\n",
    "        batch_end = min((k + 1) * batch_size, n_samples)\n",
    "        current_batch_size = batch_end - batch_start\n",
    "        x_list = []\n",
    "        y_list = []\n",
    "        max_len_token = 0\n",
    "        for idx in order[batch_start: batch_end]:\n",
    "            x_list.append(words2idxs(tokens[idx]))\n",
    "            y_list.append(tags2idxs(tags[idx]))\n",
    "            max_len_token = max(max_len_token, len(tags[idx]))\n",
    "            \n",
    "        # Fill in the data into numpy nd-arrays filled with padding indices.\n",
    "        x = np.ones([current_batch_size, max_len_token], dtype=np.int32) * token2idx['<PAD>']\n",
    "        y = np.ones([current_batch_size, max_len_token], dtype=np.int32) * tag2idx['O']\n",
    "        lengths = np.zeros(current_batch_size, dtype=np.int32)\n",
    "        for n in range(current_batch_size):\n",
    "            utt_len = len(x_list[n])\n",
    "            x[n, :utt_len] = x_list[n]\n",
    "            lengths[n] = utt_len\n",
    "            y[n, :utt_len] = y_list[n]\n",
    "        yield x, y, lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Bidirectional RNN with Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need both right and left context of a token. Hence I am using Bidirectional RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "class BiLSTMModel():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Placeholders\n",
    "\n",
    "Placeholders are created for the following data we need to input into the RNN: -------\n",
    "\n",
    "input_batch — sequences of words (the shape equals to [batch_size, sequence_len]);\n",
    "\n",
    "ground_truth_tags — sequences of tags (the shape equals to [batch_size, sequence_len]);\n",
    "\n",
    "lengths — lengths of not padded sequences (the shape equals to [batch_size]);\n",
    "\n",
    "dropout_ph — dropout keep probability; this placeholder has a predefined value 1;\n",
    "\n",
    "learning_rate_ph — learning rate; we need this placeholder because we want to change the value during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that declares the placeholders to be fed into the model\n",
    "def declare_placeholders(self):\n",
    "    # Placeholders for input and ground truth output.\n",
    "    self.input_batch = tf.placeholder(dtype=tf.int32, shape=[None, None], name='input_batch') \n",
    "    self.ground_truth_tags = tf.placeholder(dtype=tf.int32, shape=[None, None], name='ground_truth_tags')\n",
    "  \n",
    "    # Placeholder for lengths of the sequences.\n",
    "    self.lengths = tf.placeholder(dtype=tf.int32, shape=[None], name='lengths') \n",
    "    \n",
    "    # Placeholder for a dropout keep probability. default set to 0\n",
    "    self.dropout_ph = tf.placeholder_with_default(tf.cast(1.0, tf.float32), shape=[])\n",
    "    \n",
    "    # Placeholder for a learning rate (tf.float32).\n",
    "    self.learning_rate_ph = tf.placeholder(dtype=tf.float32, shape=[], name='learning_rate_placeholder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the declare placeholder function to the BiLSTMModel class\n",
    "BiLSTMModel.__declare_placeholders = classmethod(declare_placeholders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparatory Steps for Tensorflow BiRNN Cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Embedding matrix (tensorflow Variable) with random initialization\n",
    "\n",
    "2. Create Bidirectional RNN Cells - Using BasicLSTM Cell\n",
    "\n",
    "3. Wrap cells with Dropout Wrapper\n",
    "\n",
    "4. Build Computational Graph\n",
    "    \n",
    "    Look up embeddings for input batch in the embedding matrix\n",
    "    \n",
    "    Pass embeddings through Bidirectional Dynamic RNN with specified forward and backwards cells\n",
    "    (Use lengths placeholders to avoid computation on padding tokens)\n",
    "    \n",
    "    Create a dense layer on top with outputs set to loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_layers(self, vocabulary_size, embedding_dim, n_hidden_rnn, n_tags):\n",
    "    # Embedding matrix:\n",
    "    initial_embedding_matrix = np.random.randn(vocabulary_size, embedding_dim) / np.sqrt(embedding_dim)\n",
    "    # Making it a tf var\n",
    "    embedding_matrix_variable = tf.Variable(dtype=tf.float32, initial_value=initial_embedding_matrix,\n",
    "                                           name='embeddings_matrix')\n",
    "    # Forward and Backward LSTM cells\n",
    "    \n",
    "    forward_cell = tf.nn.rnn_cell.DropoutWrapper(tf.nn.rnn_cell.BasicLSTMCell(num_units=n_hidden_rnn),\n",
    "                                                 input_keep_prob=self.dropout_ph,\n",
    "                                                 output_keep_prob=self.dropout_ph,\n",
    "                                                 state_keep_prob=self.dropout_ph)\n",
    "    backward_cell = tf.nn.rnn_cell.DropoutWrapper(tf.nn.rnn_cell.BasicLSTMCell(num_units=n_hidden_rnn),\n",
    "                                              input_keep_prob=self.dropout_ph,\n",
    "                                              output_keep_prob=self.dropout_ph,\n",
    "                                              state_keep_prob=self.dropout_ph)\n",
    "    \n",
    "#     forward_cell =  tf.nn.rnn_cell.DropoutWrapper(tf.nn.rnn_cell.BasicLSTMCell(num_units=n_hidden_rnn),input_keep_prob=self.dropout_ph, output_keep_prob=self.dropout_ph, state_keep_prob=self.dropout_ph)\n",
    "#     backward_cell = tf.nn.rnn_cell.DropoutWrapper(tf.nn.rnn_cell.BasicLSTMCell(num_units=n_hidden_rnn),input_keep_prob=self.dropout_ph, output_keep_prob=self.dropout_ph, state_keep_prob=self.dropout_ph)\n",
    "    # Look up for embeddings for self.input_batch\n",
    "    embeddings = tf.nn.embedding_lookup(embedding_matrix_variable, self.input_batch)\n",
    "    \n",
    "    # Pass them (fw, bw cells; embeddings, length) through DynBiRNN\n",
    "    (rnn_output_fw, rnn_output_bw), _ = tf.nn.bidirectional_dynamic_rnn(cell_fw=forward_cell,\n",
    "                                                                        cell_bw=backward_cell,\n",
    "                                                                        inputs=embeddings,\n",
    "                                                                        sequence_length=self.lengths,\n",
    "                                                                        dtype=tf.float32)\n",
    "    rnn_output = tf.concat([rnn_output_fw, rnn_output_bw], axis=2)\n",
    "    \n",
    "    # Dense layer on top\n",
    "    self.logits = tf.layers.dense(rnn_output, n_tags, activation=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "BiLSTMModel.__build_layers = classmethod(build_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying softmax to the last layer and applying argmax to get actual predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_predictions(self):\n",
    "    softmax_output = tf.nn.softmax(self.logits)\n",
    "    self.predictions = tf.argmax(softmax_output, axis=-1)\n",
    "    \n",
    "BiLSTMModel.__compute_predictions = classmethod(compute_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the cross entropy loss with logits(not softmax probabilities). Also mask PAD terms before computing mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(self, n_tags, PAD_index):\n",
    "    ground_truth_tags_one_hot = tf.one_hot(self.ground_truth_tags, n_tags)\n",
    "    loss_tensor = tf.nn.softmax_cross_entropy_with_logits_v2(labels=ground_truth_tags_one_hot,\n",
    "                                                             logits=self.logits)\n",
    "    mask = tf.cast(tf.not_equal(loss_tensor, PAD_index), tf.float32)\n",
    "    self.loss = tf.reduce_mean(tf.multiply(loss_tensor, mask))\n",
    "    \n",
    "BiLSTMModel.__compute_loss = classmethod(compute_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Adam Optimimzer with the default B1, B2, epsilon and user defined eta.\n",
    "To prevent exploding gradient, using clipping from clip_by_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_optimization(self):\n",
    "    # Creating optimzer with Adam (default Params)\n",
    "    self.optimizer = tf.train.AdamOptimizer(learning_rate=self.learning_rate_ph, beta1=0.9, beta2=0.999, epsilon=1e-8)\n",
    "    self.grads_and_vars = self.optimizer.compute_gradients(self.loss)\n",
    "    # Gradient Clipping\n",
    "    clip_norm = tf.cast(1.0, tf.float32)\n",
    "    # I didnt write this bottom epic one liner\n",
    "    self.grads_and_vars =  [(None, var) if grad is None else (tf.clip_by_norm(grad, clip_norm), var) for grad, var in self.grads_and_vars]    \n",
    "    self.train_op = self.optimizer.apply_gradients(self.grads_and_vars)\n",
    "    \n",
    "BiLSTMModel.__perform_optimization = classmethod(perform_optimization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(self, vocabulary_size, n_tags, embedding_dim, n_hidden_rnn, PAD_index):\n",
    "    self.__declare_placeholders()\n",
    "    self.__build_layers(vocabulary_size, embedding_dim, n_hidden_rnn, n_tags)\n",
    "    self.__compute_predictions()\n",
    "    self.__compute_loss(n_tags, PAD_index)\n",
    "    self.__perform_optimization()\n",
    "\n",
    "BiLSTMModel.__init__ = classmethod(init_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Network and Predicting the Named Entity Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train on a batch\n",
    "def train_on_batch(self, session, x_batch, y_batch, lengths, learning_rate, dropout_keep_probability):\n",
    "    feed_dict = {self.input_batch: x_batch,\n",
    "                 self.ground_truth_tags: y_batch,\n",
    "                 self.learning_rate_ph: learning_rate,\n",
    "                 self.dropout_ph: dropout_keep_probability,\n",
    "                 self.lengths: lengths}\n",
    "    \n",
    "    session.run(self.train_op, feed_dict=feed_dict)\n",
    "BiLSTMModel.train_on_batch = classmethod(train_on_batch)\n",
    "\n",
    "# Function to predict from a batch\n",
    "def predict_for_batch(self, session, x_batch, lengths):\n",
    "    feed_dict={self.input_batch:x_batch,\n",
    "               self.lengths:lengths}\n",
    "    predictions = session.run(self.predictions, feed_dict=feed_dict)\n",
    "    return predictions\n",
    "BiLSTMModel.predict_for_batch = classmethod(predict_for_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CODE TAKEN FROM\n",
    "## https://github.com/hse-aml/natural-language-processing/blob/master/week2/evaluation.py\n",
    "from collections import OrderedDict\n",
    "\n",
    "def _update_chunk(candidate, prev, current_tag, current_chunk, current_pos, prediction=False):\n",
    "    if candidate == 'B-' + current_tag:\n",
    "        if len(current_chunk) > 0 and len(current_chunk[-1]) == 1:\n",
    "                current_chunk[-1].append(current_pos - 1)\n",
    "        current_chunk.append([current_pos])\n",
    "    elif candidate == 'I-' + current_tag:\n",
    "        if prediction and (current_pos == 0 or current_pos > 0 and prev.split('-', 1)[-1] != current_tag):\n",
    "            current_chunk.append([current_pos])\n",
    "        if not prediction and (current_pos == 0 or current_pos > 0 and prev == 'O'):\n",
    "            current_chunk.append([current_pos])\n",
    "    elif current_pos > 0 and prev.split('-', 1)[-1] == current_tag:\n",
    "        if len(current_chunk) > 0:\n",
    "            current_chunk[-1].append(current_pos - 1)\n",
    "\n",
    "def _update_last_chunk(current_chunk, current_pos):\n",
    "    if len(current_chunk) > 0 and len(current_chunk[-1]) == 1:\n",
    "        current_chunk[-1].append(current_pos - 1)\n",
    "\n",
    "def _tag_precision_recall_f1(tp, fp, fn):\n",
    "    precision, recall, f1 = 0, 0, 0\n",
    "    if tp + fp > 0:\n",
    "        precision = tp / (tp + fp) * 100\n",
    "    if tp + fn > 0:\n",
    "        recall = tp / (tp + fn) * 100\n",
    "    if precision + recall > 0:\n",
    "        f1 = 2 * precision * recall / (precision + recall)\n",
    "    return precision, recall, f1\n",
    "\n",
    "def _aggregate_metrics(results, total_correct):\n",
    "    total_true_entities = 0\n",
    "    total_predicted_entities = 0\n",
    "    total_precision = 0\n",
    "    total_recall = 0\n",
    "    total_f1 = 0\n",
    "    for tag, tag_metrics in results.items():\n",
    "        n_pred = tag_metrics['n_predicted_entities']\n",
    "        n_true = tag_metrics['n_true_entities']\n",
    "        total_true_entities += n_true\n",
    "        total_predicted_entities += n_pred\n",
    "        total_precision += tag_metrics['precision'] * n_pred\n",
    "        total_recall += tag_metrics['recall'] * n_true\n",
    "    \n",
    "    accuracy = 0\n",
    "    if total_true_entities > 0:\n",
    "        accuracy = total_correct / total_true_entities * 100\n",
    "    else:\n",
    "        print('CAUTION! Accuracy equals zero because there are no '\\\n",
    "              'correct entities. Check the correctness of your data.')\n",
    "    if total_predicted_entities > 0:\n",
    "        total_precision = total_precision / total_predicted_entities\n",
    "    total_recall = total_recall / total_true_entities\n",
    "    if total_precision + total_recall > 0:\n",
    "        total_f1 = 2 * total_precision * total_recall / (total_precision + total_recall)\n",
    "    return total_true_entities, total_predicted_entities, \\\n",
    "           total_precision, total_recall, total_f1, accuracy\n",
    "\n",
    "def _print_info(n_tokens, total_true_entities, total_predicted_entities, total_correct):\n",
    "    print('processed {len} tokens ' \\\n",
    "          'with {tot_true} phrases; ' \\\n",
    "          'found: {tot_pred} phrases; ' \\\n",
    "          'correct: {tot_cor}.\\n'.format(len=n_tokens,\n",
    "                                         tot_true=total_true_entities,\n",
    "                                         tot_pred=total_predicted_entities,\n",
    "                                         tot_cor=total_correct))\n",
    "\n",
    "def _print_metrics(accuracy, total_precision, total_recall, total_f1):\n",
    "    print('precision:  {tot_prec:.2f}%; ' \\\n",
    "          'recall:  {tot_recall:.2f}%; ' \\\n",
    "          'F1:  {tot_f1:.2f}\\n'.format(acc=accuracy,\n",
    "                                           tot_prec=total_precision,\n",
    "                                           tot_recall=total_recall,\n",
    "                                           tot_f1=total_f1))\n",
    "\n",
    "def _print_tag_metrics(tag, tag_results):\n",
    "    print(('\\t%12s' % tag) + ': precision:  {tot_prec:6.2f}%; ' \\\n",
    "                               'recall:  {tot_recall:6.2f}%; ' \\\n",
    "                               'F1:  {tot_f1:6.2f}; ' \\\n",
    "                               'predicted:  {tot_predicted:4d}\\n'.format(tot_prec=tag_results['precision'],\n",
    "                                                                         tot_recall=tag_results['recall'],\n",
    "                                                                         tot_f1=tag_results['f1'],\n",
    "                                                                         tot_predicted=tag_results['n_predicted_entities']))\n",
    "\n",
    "def precision_recall_f1(y_true, y_pred, print_results=True, short_report=False):\n",
    "    # Find all tags\n",
    "    tags = sorted(set(tag[2:] for tag in y_true + y_pred if tag != 'O'))\n",
    "\n",
    "    results = OrderedDict((tag, OrderedDict()) for tag in tags)\n",
    "    n_tokens = len(y_true)\n",
    "    total_correct = 0\n",
    "\n",
    "    # For eval_conll_try we find all chunks in the ground truth and prediction\n",
    "    # For each chunk we store starting and ending indices\n",
    "    for tag in tags:\n",
    "        true_chunk = list()\n",
    "        predicted_chunk = list()\n",
    "        for position in range(n_tokens):\n",
    "            _update_chunk(y_true[position], y_true[position - 1], tag, true_chunk, position)\n",
    "            _update_chunk(y_pred[position], y_pred[position - 1], tag, predicted_chunk, position, True)\n",
    "\n",
    "        _update_last_chunk(true_chunk, position)\n",
    "        _update_last_chunk(predicted_chunk, position)\n",
    "\n",
    "        # Then we find all correctly classified intervals\n",
    "        # True positive results\n",
    "        tp = sum(chunk in predicted_chunk for chunk in true_chunk)\n",
    "        total_correct += tp\n",
    "\n",
    "        # And then just calculate errors of the first and second kind\n",
    "        # False negative\n",
    "        fn = len(true_chunk) - tp\n",
    "        # False positive\n",
    "        fp = len(predicted_chunk) - tp\n",
    "        precision, recall, f1 = _tag_precision_recall_f1(tp, fp, fn)\n",
    "\n",
    "        results[tag]['precision'] = precision\n",
    "        results[tag]['recall'] = recall\n",
    "        results[tag]['f1'] = f1\n",
    "        results[tag]['n_predicted_entities'] = len(predicted_chunk)\n",
    "        results[tag]['n_true_entities'] = len(true_chunk)\n",
    "\n",
    "    total_true_entities, total_predicted_entities, \\\n",
    "           total_precision, total_recall, total_f1, accuracy = _aggregate_metrics(results, total_correct)\n",
    "\n",
    "    if print_results:\n",
    "        _print_info(n_tokens, total_true_entities, total_predicted_entities, total_correct)\n",
    "        _print_metrics(accuracy, total_precision, total_recall, total_f1)\n",
    "\n",
    "        if not short_report:\n",
    "            for tag, tag_results in results.items():\n",
    "                _print_tag_metrics(tag, tag_results)\n",
    "    return results\n",
    "\n",
    "def predict_tags(model, session, token_idxs_batch, lengths):\n",
    "    \"\"\"Performs predictions and transforms indices to tokens and tags.\"\"\"\n",
    "    \n",
    "    tag_idxs_batch = model.predict_for_batch(session, token_idxs_batch, lengths)\n",
    "    \n",
    "    tags_batch, tokens_batch = [], []\n",
    "    for tag_idxs, token_idxs in zip(tag_idxs_batch, token_idxs_batch):\n",
    "        tags, tokens = [], []\n",
    "        for tag_idx, token_idx in zip(tag_idxs, token_idxs):\n",
    "            tags.append(idx2tag[tag_idx])\n",
    "            tokens.append(idx2token[token_idx])\n",
    "        tags_batch.append(tags)\n",
    "        tokens_batch.append(tokens)\n",
    "        \n",
    "    return tags_batch, tokens_batch\n",
    "    \n",
    "    \n",
    "def eval_conll(model, session, tokens, tags, short_report=True):\n",
    "    \"\"\"Computes NER quality measures using CONLL shared task script.\"\"\"\n",
    "    \n",
    "    y_true, y_pred = [], []\n",
    "    for x_batch, y_batch, lengths in batches_generator(1, tokens, tags):\n",
    "        tags_batch, tokens_batch = predict_tags(model, session, x_batch, lengths)\n",
    "        if len(x_batch[0]) != len(tags_batch[0]):\n",
    "            raise Exception(\"Incorrect length of prediction for the input, \"\n",
    "                            \"expected length: %i, got: %i\" % (len(x_batch[0]), len(tags_batch[0])))\n",
    "        predicted_tags = []\n",
    "        ground_truth_tags = []\n",
    "        for gt_tag_idx, pred_tag, token in zip(y_batch[0], tags_batch[0], tokens_batch[0]): \n",
    "            if token != '<PAD>':\n",
    "                ground_truth_tags.append(idx2tag[gt_tag_idx])\n",
    "                predicted_tags.append(pred_tag)\n",
    "\n",
    "        # We extend every prediction and ground truth sequence with 'O' tag\n",
    "        # to indicate a possible end of entity.\n",
    "        y_true.extend(ground_truth_tags + ['O'])\n",
    "        y_pred.extend(predicted_tags + ['O'])\n",
    "        \n",
    "    results = precision_recall_f1(y_true, y_pred, print_results=True, short_report=short_report)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the training and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/themadscientist/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-15-7802f83f6196>:9: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-15-7802f83f6196>:28: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /home/themadscientist/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/rnn.py:443: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /home/themadscientist/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/rnn.py:626: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/themadscientist/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/rnn_cell_impl.py:1259: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From <ipython-input-15-7802f83f6196>:32: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "model = BiLSTMModel(len(idx2token),len(idx2tag),200,200,token2idx['<PAD>'])\n",
    "\n",
    "batch_size = 32\n",
    "n_epochs = 5\n",
    "learning_rate = 0.007\n",
    "learning_rate_decay = np.sqrt(2)\n",
    "dropout_keep_probability = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training... \n",
      "\n",
      "-------------------- Epoch 1 of 5 --------------------\n",
      "Train data evaluation:\n",
      "processed 105778 tokens with 4489 phrases; found: 80755 phrases; correct: 204.\n",
      "\n",
      "precision:  0.25%; recall:  4.54%; F1:  0.48\n",
      "\n",
      "Validation data evaluation:\n",
      "processed 12836 tokens with 537 phrases; found: 9701 phrases; correct: 30.\n",
      "\n",
      "precision:  0.31%; recall:  5.59%; F1:  0.59\n",
      "\n",
      "-------------------- Epoch 2 of 5 --------------------\n",
      "Train data evaluation:\n",
      "processed 105778 tokens with 4489 phrases; found: 1793 phrases; correct: 561.\n",
      "\n",
      "precision:  31.29%; recall:  12.50%; F1:  17.86\n",
      "\n",
      "Validation data evaluation:\n",
      "processed 12836 tokens with 537 phrases; found: 163 phrases; correct: 59.\n",
      "\n",
      "precision:  36.20%; recall:  10.99%; F1:  16.86\n",
      "\n",
      "-------------------- Epoch 3 of 5 --------------------\n",
      "Train data evaluation:\n",
      "processed 105778 tokens with 4489 phrases; found: 4570 phrases; correct: 2282.\n",
      "\n",
      "precision:  49.93%; recall:  50.84%; F1:  50.38\n",
      "\n",
      "Validation data evaluation:\n",
      "processed 12836 tokens with 537 phrases; found: 347 phrases; correct: 161.\n",
      "\n",
      "precision:  46.40%; recall:  29.98%; F1:  36.43\n",
      "\n",
      "-------------------- Epoch 4 of 5 --------------------\n",
      "Train data evaluation:\n",
      "processed 105778 tokens with 4489 phrases; found: 4735 phrases; correct: 3429.\n",
      "\n",
      "precision:  72.42%; recall:  76.39%; F1:  74.35\n",
      "\n",
      "Validation data evaluation:\n",
      "processed 12836 tokens with 537 phrases; found: 385 phrases; correct: 181.\n",
      "\n",
      "precision:  47.01%; recall:  33.71%; F1:  39.26\n",
      "\n",
      "-------------------- Epoch 5 of 5 --------------------\n",
      "Train data evaluation:\n",
      "processed 105778 tokens with 4489 phrases; found: 4672 phrases; correct: 3936.\n",
      "\n",
      "precision:  84.25%; recall:  87.68%; F1:  85.93\n",
      "\n",
      "Validation data evaluation:\n",
      "processed 12836 tokens with 537 phrases; found: 396 phrases; correct: 192.\n",
      "\n",
      "precision:  48.48%; recall:  35.75%; F1:  41.16\n",
      "\n",
      "...training finished.\n",
      "CPU times: user 13min 46s, sys: 53 s, total: 14min 39s\n",
      "Wall time: 5min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "print('Start training... \\n')\n",
    "for epoch in range(n_epochs):\n",
    "    # For each epoch evaluate the model on train and validation data\n",
    "    print('-' * 20 + ' Epoch {} '.format(epoch+1) + 'of {} '.format(n_epochs) + '-' * 20)\n",
    "    print('Train data evaluation:')\n",
    "    eval_conll(model, sess, train_tokens, train_tags, short_report=True)\n",
    "    print('Validation data evaluation:')\n",
    "    eval_conll(model, sess, validation_tokens, validation_tags, short_report=True)\n",
    "    \n",
    "    # Train the model\n",
    "    for x_batch, y_batch, lengths in batches_generator(batch_size, train_tokens, train_tags):\n",
    "        model.train_on_batch(sess, x_batch, y_batch, lengths, learning_rate, dropout_keep_probability)\n",
    "        \n",
    "    # Decaying the learning rate\n",
    "    learning_rate = learning_rate / learning_rate_decay\n",
    "    \n",
    "print('...training finished.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Train set quality: --------------------\n",
      "processed 105778 tokens with 4489 phrases; found: 4608 phrases; correct: 4166.\n",
      "\n",
      "precision:  90.41%; recall:  92.80%; F1:  91.59\n",
      "\n",
      "\t     company: precision:   92.60%; recall:   95.33%; F1:   93.95; predicted:   662\n",
      "\n",
      "\t    facility: precision:   87.12%; recall:   90.45%; F1:   88.75; predicted:   326\n",
      "\n",
      "\t     geo-loc: precision:   94.30%; recall:   97.99%; F1:   96.11; predicted:  1035\n",
      "\n",
      "\t       movie: precision:   63.86%; recall:   77.94%; F1:   70.20; predicted:    83\n",
      "\n",
      "\t musicartist: precision:   80.48%; recall:   87.07%; F1:   83.64; predicted:   251\n",
      "\n",
      "\t       other: precision:   88.12%; recall:   89.17%; F1:   88.64; predicted:   766\n",
      "\n",
      "\t      person: precision:   94.97%; recall:   95.94%; F1:   95.45; predicted:   895\n",
      "\n",
      "\t     product: precision:   87.80%; recall:   92.77%; F1:   90.21; predicted:   336\n",
      "\n",
      "\t  sportsteam: precision:   88.63%; recall:   86.18%; F1:   87.38; predicted:   211\n",
      "\n",
      "\t      tvshow: precision:   72.09%; recall:   53.45%; F1:   61.39; predicted:    43\n",
      "\n",
      "-------------------- Validation set quality: --------------------\n",
      "processed 12836 tokens with 537 phrases; found: 404 phrases; correct: 188.\n",
      "\n",
      "precision:  46.53%; recall:  35.01%; F1:  39.96\n",
      "\n",
      "\t     company: precision:   62.50%; recall:   52.88%; F1:   57.29; predicted:    88\n",
      "\n",
      "\t    facility: precision:   42.31%; recall:   32.35%; F1:   36.67; predicted:    26\n",
      "\n",
      "\t     geo-loc: precision:   70.73%; recall:   51.33%; F1:   59.49; predicted:    82\n",
      "\n",
      "\t       movie: precision:    0.00%; recall:    0.00%; F1:    0.00; predicted:    10\n",
      "\n",
      "\t musicartist: precision:   23.53%; recall:   14.29%; F1:   17.78; predicted:    17\n",
      "\n",
      "\t       other: precision:   37.70%; recall:   28.40%; F1:   32.39; predicted:    61\n",
      "\n",
      "\t      person: precision:   50.94%; recall:   24.11%; F1:   32.73; predicted:    53\n",
      "\n",
      "\t     product: precision:   11.63%; recall:   14.71%; F1:   12.99; predicted:    43\n",
      "\n",
      "\t  sportsteam: precision:   20.83%; recall:   25.00%; F1:   22.73; predicted:    24\n",
      "\n",
      "\t      tvshow: precision:    0.00%; recall:    0.00%; F1:    0.00; predicted:     0\n",
      "\n",
      "-------------------- Test set quality: --------------------\n",
      "processed 13258 tokens with 604 phrases; found: 506 phrases; correct: 231.\n",
      "\n",
      "precision:  45.65%; recall:  38.25%; F1:  41.62\n",
      "\n",
      "\t     company: precision:   60.71%; recall:   40.48%; F1:   48.57; predicted:    56\n",
      "\n",
      "\t    facility: precision:   39.02%; recall:   34.04%; F1:   36.36; predicted:    41\n",
      "\n",
      "\t     geo-loc: precision:   72.58%; recall:   54.55%; F1:   62.28; predicted:   124\n",
      "\n",
      "\t       movie: precision:    0.00%; recall:    0.00%; F1:    0.00; predicted:    16\n",
      "\n",
      "\t musicartist: precision:    7.14%; recall:    7.41%; F1:    7.27; predicted:    28\n",
      "\n",
      "\t       other: precision:   36.27%; recall:   35.92%; F1:   36.10; predicted:   102\n",
      "\n",
      "\t      person: precision:   60.61%; recall:   38.46%; F1:   47.06; predicted:    66\n",
      "\n",
      "\t     product: precision:   10.53%; recall:   14.29%; F1:   12.12; predicted:    38\n",
      "\n",
      "\t  sportsteam: precision:   24.24%; recall:   25.81%; F1:   25.00; predicted:    33\n",
      "\n",
      "\t      tvshow: precision:    0.00%; recall:    0.00%; F1:    0.00; predicted:     2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('-' * 20 + ' Train set quality: ' + '-' * 20)\n",
    "train_results = eval_conll(model, sess, train_tokens, train_tags, short_report=False)\n",
    "\n",
    "print('-' * 20 + ' Validation set quality: ' + '-' * 20)\n",
    "validation_results =eval_conll(model, sess, validation_tokens, validation_tags, short_report=False)\n",
    "\n",
    "print('-' * 20 + ' Test set quality: ' + '-' * 20)\n",
    "test_results = eval_conll(model, sess, test_tokens, test_tags, short_report=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read Above Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get GPUs from Negi Sir\n",
    "\n",
    "Use GRUs instead of LSTMs and see the difference"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
